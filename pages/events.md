---
layout: page
title: Events
permalink: /events/
image:
image_full: true
class:
summary: Make the Government Work Better through Testing and Learning
---
Join OES and numerous agency partners to learn how the Federal government uses repeat testing and leverages administrative data to improve outcomes. GSA Administrator Emily Murphy will introduce the event highlighting government-wide progress using data as a strategic asset. In three brief sessions following, distinguished agency partners and academic collaborators will present case studies and lessons learned from rapid cycle testing, building a portfolio of evidence, and transparent evaluation. 

- <b>When</b>: November 7, 2018 10:00 AM - 12:00 PM
- <b>Where</b>: 1800 F ST NW, Washington DC 20405, Room 1461 
- <b>Who should attend?</b> Federal employees, academics and others interested in learning more.
- <b>Register</b>: <a href="https://goo.gl/forms/VhRduCS5BVFScFv92">Sign Up Here </a>

<i>Note: If you are an OMB or other agency employee where Google Forms does not work, email oes@gsa.gov to register</i>

Following this event, the <a href="https://behavioralpolicy.org/">Behavioral Science and Policy Association (BSPA)</a> has asked leading experts to facilitate a series of workshops for Federal employees on Behavioral Science 101. Stay tuned for more information on this training.

## Make the Government Work Better through Rapid Cycle Testing

In this segment, partners from the Department of Health and Human Services (HHS), Social Security Administration (SSA) and the Department of Housing and Urban Development (HUD) will share new results and lessons learned from conducting repeated experimental tests. These leaders will address priority topics such as overprescribing of certain medications, energy cost-savings, and making government communications more effective. 

Speakers include: 
- Jackson Le (Pharmacist, Division of Provider Investigations and Audits, Investigations and Audits Group, Center for Program Integrity, Centers for Medicare and Medicaid Services) will discuss how HHS used CMS Medicare Part D claims data to support repeated testing, and decreased overprescribing by 11%.
- Katherine Bent (Associate Commissioner; Office of Research, Demonstration and Employment Support; SSA) will discuss how SSA administrative data has been used to communicate program eligibility about Supplemental Security Income.  
- Calvin Johnson (Deputy Assistant Secretary; Policy Development and Research; Office of Research, Evaluation and Monitoring; HUD) will discuss how HUDâ€™s Division of Affordable Housing and Building Technology is working with Housing Authorities to use Wireless Energy Modules to measure energy use and test efforts to drive down energy costs. 
- Mary Steffel (Assistant Professor, Northeastern University) will review key lessons from repeat testing to design effective government communications. 

## Make the Government Work Better through a Portfolio of Evidence

This segment will highlight findings from tests with HHS, the Department of Veterans Affairs (VA), Louisiana Department of Health and Centers for Medicare and Medicaid Services (CMS) on low-cost and scalable program changes to improve vaccination rates among various populations such as Veterans, children and adolescents, and adults 65 and over.  

Speakers include: 
- Gretchen Chapman (Professor, Carnegie Mellon University) will share how behavioral science insights have played a role in increasing vaccination rates in previous studies
- David Yokum (Brown University) will discuss how CMS sent outreach to Medicare beneficiaries to increase flu vaccination rates
- Troy Knighton (Program Manager, National Seasonal Flu & IDPIO, National Center for Health Promotion and Disease Prevention, VHA) will share results from two evaluations modifying outreach to Veterans to encourage flu vaccination
- Pompa Debroy (Associate Fellow, OES) will share what is next for the OES vaccine portfolio

## Make the Government Work Better through Transparent Evaluation 

In this final portion, speakers will discuss why transparency about evaluation methods is a good idea not only as a matter of public accountability but also as a tool for strengthening federal evaluation. The session will focus, in particular, on pre-registration of study designs and analysis plans. Speakers will discuss why the results of pre-registered evaluations are generally more reliable for policy and program design; address some challenges to preregistration in the government context (both real and perceived); and present examples of recent evaluations that benefited from pre-registration.
